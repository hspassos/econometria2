{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11557ce",
   "metadata": {},
   "source": [
    "1. Estime os parâmetros $\\beta_k$, $\\beta_l$ por GMM utilizando o estimador apresentado acima. Escreva um programa em Matlab utilizando o solver fminsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b746bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chilean = pd.read_csv('chilean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a03f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.824\n",
      "Model:                            OLS   Adj. R-squared:                  0.823\n",
      "Method:                 Least Squares   F-statistic:                     843.9\n",
      "Date:                Wed, 18 Jun 2025   Prob (F-statistic):               0.00\n",
      "Time:                        13:38:09   Log-Likelihood:                -2369.4\n",
      "No. Observations:                2544   AIC:                             4769.\n",
      "Df Residuals:                    2529   BIC:                             4856.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.2094      0.140     65.592      0.000       8.934       9.485\n",
      "k              0.0015      0.019      0.078      0.937      -0.036       0.039\n",
      "l              1.0511      0.047     22.236      0.000       0.958       1.144\n",
      "l_4           -0.0132      0.005     -2.724      0.006      -0.023      -0.004\n",
      "k_l_3          0.0096      0.005      1.788      0.074      -0.001       0.020\n",
      "k2_l2         -0.0012      0.002     -0.639      0.523      -0.005       0.003\n",
      "k3_l          -0.0006      0.000     -2.216      0.027      -0.001   -7.06e-05\n",
      "k_4            0.0002   1.94e-05      8.620      0.000       0.000       0.000\n",
      "m_4            0.0055      0.001      6.179      0.000       0.004       0.007\n",
      "k_m_3         -0.0097      0.001     -7.630      0.000      -0.012      -0.007\n",
      "k2_m2          0.0049      0.001      7.245      0.000       0.004       0.006\n",
      "k3_m          -0.0008      0.000     -5.480      0.000      -0.001      -0.001\n",
      "m_l_3          0.0092      0.003      3.152      0.002       0.003       0.015\n",
      "m2_l2         -0.0160      0.004     -4.533      0.000      -0.023      -0.009\n",
      "m3_l           0.0082      0.002      4.881      0.000       0.005       0.012\n",
      "==============================================================================\n",
      "Omnibus:                       79.225   Durbin-Watson:                   0.700\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              169.446\n",
      "Skew:                           0.178   Prob(JB):                     1.60e-37\n",
      "Kurtosis:                       4.213   Cond. No.                     3.52e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.52e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      " Intercepto do primeiro estágio: 9.209416673947127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "df = chilean.rename(columns={'Y': 'y', 'sX': 'k', 'pX': 'm', 'fX1': 'fx1', 'fX2': 'fx2'}).copy()\n",
    "\n",
    "\n",
    "# l = ln(exp(fx1) + exp(fx2))\n",
    "df['l'] = np.log(np.exp(df['fx1']) + np.exp(df['fx2']))\n",
    "\n",
    "# Selecionar variáveis relevantes e criar uma cópia explícita\n",
    "df_panel = df[['idvar', 'timevar', 'y', 'k', 'l', 'm']].copy()\n",
    "\n",
    "# Ordenar dados para lagging\n",
    "df_panel.sort_values(['idvar', 'timevar'], inplace=True)\n",
    "\n",
    "# Primeiro Estágio: OLS\n",
    "\n",
    "# Criar termos polinomiais de 4ª ordem para f^-1(k, l, m)\n",
    "X_stage1 = pd.DataFrame(index=df_panel.index)\n",
    "X_stage1['const'] = 1\n",
    "X_stage1['k'] = df_panel['k']\n",
    "X_stage1['l'] = df_panel['l']\n",
    "\n",
    "# $\\sum_{i=0}^4 \\beta k^i * l^{4-i}$\n",
    "X_stage1['l_4'] = df_panel['l']**4\n",
    "X_stage1['k_l_3'] = df_panel['k'] * (df_panel['l']**3)\n",
    "X_stage1['k2_l2'] = (df_panel['k']**2) * (df_panel['l']**2)\n",
    "X_stage1['k3_l'] = (df_panel['k']**3) * df_panel['l']\n",
    "X_stage1['k_4'] = df_panel['k']**4\n",
    "\n",
    "# m^4 + k*m^3 + k^2*m^2 + k^3*m (k^4 já foi definido)\n",
    "X_stage1['m_4'] = df_panel['m']**4\n",
    "X_stage1['k_m_3'] = df_panel['k'] * (df_panel['m']**3)\n",
    "X_stage1['k2_m2'] = (df_panel['k']**2) * (df_panel['m']**2)\n",
    "X_stage1['k3_m'] = (df_panel['k']**3) * df_panel['m']\n",
    "\n",
    "# m*l^3 + m^2*l^2 + m^3*l (l^4 e m^4 já foram definidos)\n",
    "X_stage1['m_l_3'] = df_panel['m'] * (df_panel['l']**3)\n",
    "X_stage1['m2_l2'] = (df_panel['m']**2) * (df_panel['l']**2)\n",
    "X_stage1['m3_l'] = (df_panel['m']**3) * df_panel['l']\n",
    "\n",
    "y_stage1 = df_panel['y']\n",
    "\n",
    "\n",
    "data_stage1_full = pd.concat([y_stage1, X_stage1], axis=1)\n",
    "data_stage1_clean = data_stage1_full.dropna()\n",
    "\n",
    "y_stage1_clean = data_stage1_clean['y']\n",
    "X_stage1_clean = data_stage1_clean.drop(columns=['y'])\n",
    "\n",
    "model_stage1 = sm.OLS(y_stage1_clean, X_stage1_clean)\n",
    "results_stage1 = model_stage1.fit()\n",
    "print(results_stage1.summary())\n",
    "\n",
    "beta_0_tilde = results_stage1.params['const']\n",
    "print(f\"\\n Intercepto do primeiro estágio: {beta_0_tilde}\")\n",
    "\n",
    "# Calcular Phi_hat e adicionar de volta ao df_panel original usando o índice\n",
    "df_panel['Phi_hat'] = np.nan\n",
    "df_panel.loc[X_stage1_clean.index, 'Phi_hat'] = results_stage1.predict(X_stage1_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fa5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo Estágio: GMM\n",
    "\n",
    "# Criar variáveis defasadas (k_{t-1}, l_{t-1}, Phi_hat_{t-1})\n",
    "df_panel['k_lag1'] = df_panel.groupby('idvar')['k'].shift(1)\n",
    "df_panel['l_lag1'] = df_panel.groupby('idvar')['l'].shift(1)\n",
    "df_panel['Phi_hat_lag1'] = df_panel.groupby('idvar')['Phi_hat'].shift(1)\n",
    "\n",
    "# Selecionar apenas as colunas necessárias para o GMM\n",
    "df_stage2 = df_panel[['y', 'k', 'l', 'Phi_hat_lag1', 'k_lag1', 'l_lag1']].dropna()\n",
    "\n",
    "y_jt = df_stage2['y'].values\n",
    "k_jt = df_stage2['k'].values\n",
    "l_jt = df_stage2['l'].values\n",
    "Phi_hat_t_minus_1 = df_stage2['Phi_hat_lag1'].values\n",
    "k_jt_minus_1 = df_stage2['k_lag1'].values\n",
    "l_jt_minus_1 = df_stage2['l_lag1'].values\n",
    "\n",
    "rho_hat = 0.9528 # Valor fixo conforme a questão\n",
    "\n",
    "# Função de momentos para GMM\n",
    "def gmm_moments(params_gmm):\n",
    "    beta_k, beta_l = params_gmm\n",
    "    \n",
    "    # Resíduo u_jt da Equação (6)\n",
    "    # u_jt = y_jt - beta_0_tilde - beta_k*k_jt - beta_l*l_jt - rho_hat * (Phi_hat_{t-1} - beta_0_tilde - beta_k*k_{t-1} - beta_l*l_{t-1})\n",
    "    \n",
    "    term_current_prod = y_jt - beta_0_tilde - beta_k * k_jt - beta_l * l_jt\n",
    "    term_lagged_prod_expectation = Phi_hat_t_minus_1 - beta_0_tilde - beta_k * k_jt_minus_1 - beta_l * l_jt_minus_1\n",
    "    \n",
    "    u_jt = term_current_prod - rho_hat * term_lagged_prod_expectation\n",
    "    \n",
    "    # Condições de momento E[u_jt * Z_jt] = 0\n",
    "    # Z_jt = [k_jt, l_jt_minus_1]\n",
    "    moment1 = np.mean(u_jt * k_jt)           # Instrumento: k_jt\n",
    "    moment2 = np.mean(u_jt * l_jt_minus_1)   # Instrumento: l_jt-1\n",
    "    \n",
    "    return np.array([moment1, moment2])\n",
    "\n",
    "# Função objetivo para GMM (soma dos quadrados dos momentos)\n",
    "# Para GMM exatamente identificado, a matriz de ponderação W pode ser a identidade.\n",
    "def gmm_objective(params_gmm):\n",
    "    moments = gmm_moments(params_gmm)\n",
    "    return np.sum(moments**2) # Equivalente a m'I m\n",
    "\n",
    "# Valores iniciais para beta_k, beta_l (podem vir de um OLS simples ou serem arbitrários razoáveis)\n",
    "# Usando os coeficientes de k e l do primeiro estágio como ponto de partida pode ser uma boa ideia.\n",
    "# No entanto, a questão implica que beta_k e beta_l do primeiro estágio são diferentes dos do segundo.\n",
    "# Vamos usar valores iniciais comuns para elasticidades.\n",
    "initial_params_gmm = [0.1, 0.6] \n",
    "\n",
    "print(\"\\nSegundo Estágio - GMM:\")\n",
    "# Otimização usando Nelder-Mead (análogo ao fminsearch do Matlab)\n",
    "result_gmm = minimize(gmm_objective, initial_params_gmm, method='Nelder-Mead')\n",
    "\n",
    "print(\"Optimization successful.\")\n",
    "beta_k_gmm, beta_l_gmm = result_gmm.x\n",
    "print(f\"   Final GMM objective function value: {result_gmm.fun:.6e}\")\n",
    "print(f\"   Estimated beta_k: {beta_k_gmm:.4f}\")\n",
    "print(f\"   Estimated beta_l: {beta_l_gmm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf18ef1",
   "metadata": {},
   "source": [
    "2. Calcule a estatística de Wald (F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
